hello is that dr pi? yeah speaking, can you get us 
some transcripts from youtube? transcripts? yeah  
okay I can do that! we will be awfully grateful 
if you can do this lovely job all right thank you
hello everybody in this video we're going 
to look at how to get the transcript of a  
youtube video automatically so we're going to be 
using python code to do this so let's look at how  
we're going to get about it so firstly we want 
to get the id of the youtube video so the id is  
the last part of the url of the video that you're 
watching that you want to get the transcript from  
next we want to uh we want to add the id to our 
python code and once we've done that we can then  
pass the output and we can save it to a text 
file or we can do some NLP with it if we want so  
we've all got our own reasons for passing and 
for actually extracting the transcript anyway um  
obviously there's manual ways of doing this 
and there are browser extensions but we want  
to do this programmatically and also we 
may want to do it for many many videos  
so you don't want to sit there keep clicking 
right clicking copy and pasting and so on so
as i said the part of the i part 
of the url which represents the id  
which you will need to get is this so after the 
equals and there's a little gotcha actually which  
i'll show you in the code in a minute where 
if it begins if it begins with a backslash  
so that's what you need to do and once you've got 
the video id then it's time to install pip install  
youtube dash transcript dash api and if you're 
doing it the normal old-fashioned way pip install  
youtube underscore transcript underscore api or 
if you're using conda conda install c conda dash  
forge youtube dash transcript dash api so when you 
do it on conda you've just got hyphens instead of  
underscores this is the conda page it was last 
updated three months ago so it's very recent  
it's quite a new project actually only 248 
downloads anyway when you've installed it  
or when you want to install it using conda you'll 
get a screen like this and it'll prompt you that  
you need to uh update or install the following 
packages ca certificates certified and conda  
and just say yes to agree to these they're quite 
small um right this is the this is a screenshot of  
the of the uh the the this is a screenshot of the 
documentation couldn't get my words out then not  
getting seen honestly it's just uh like a coffee 
right from youtube underscore transcript api  
import use youtube transcript api so just copy and 
paste that from the documentation then this is the  
good bit youtube youtube transcript api dot get 
underscore transcript and then a brackets video id  
so there's no um there's no quotes or anything for 
that so just paste it straight into the brackets  
and if you were to copy what they've shown 
here you would actually just get a large  
um large python dictionary insert or multiple 
python dictionaries inside the list so  
in a minute i'll show you some code and 
i'll show you how to actually extract that  
if you want different languages you 
can specify different languages so  
what it does is actually checks in sequence so 
it will check if you put d e then it will check  
for a german transcript first and then english 
and so on and so on so you can put many many  
different flavors there and uh yeah it will 
try and get the one that you want in sequence  
in order of priority um right so this is some 
code this is what we will get when we run it so  
this is just a little taster and if you like 
this code or if you like the projects rather  
um then donate if possible to jonas de poire at 
web dot d e uh go to the go to the documentation  
and you will see his donate button there and 
if you like what i do then don't forget to  
check out red and green which is my website and 
there's links to various different things we got  
a bit of network automation my github page my 
blog where i just put a few technical notes  
rather than more than a few even data 
extraction challenges using jquery  
and working with json and apis and there we 
go so if you'd like to see some actual code  
okay so we've done the conda install we've 
installed youtube transcript api if you want to do  
it with pip then you don't need to do the cond a 
bit so this is where we do the import the module  
from youtube transcript api import youtube 
transcript api then um just a quick note here  
you can have a list of just a couple of settings 
so as i mentioned just now this is a note about  
the language settings and um also with regard to 
the video id if the video id starts with a hyphen  
you'll have to mask the hyphen using the
backslash so yeah if it's got a hyphen at the 
start you just need to put a backslash otherwise  
the uh the code will think that it's an 
argument or think it's an argument name  
so the main code if you're ready to see 
that well i've already got an extracted  
video id so all i've done is just found a 
video i found one that had subtitles and  
if it doesn't have subtitles you're getting 
that or you won't get an error but you'll  
get a notification saying that it it's not 
possible to get subtitles for this video  
so the main code out ls so that's going to be 
the list which captures the output of all of the  
subtitles so tx equals youtube transcripts 
api dot get trans get underscore transcript  
and there we can see um the parameters that you 
pass to it so you can pass to the video id the  
languages and it can also cope with proxies and 
cookies the default is no proxy and no cookies  
so the default is also english if you don't 
specify languages either so i could actually  
leave that out well i'm just for demonstration 
purposes i'm going to leave d e in here  
and you'll see what happens because when d 
e is not available it will then just go off  
and get english um be aware that these are two 
letter country codes uh what was i using the other  
day something was using three-letter country 
codes i think that may have been i don't know  
was it ginger something like that not not ginger 
itself but uh something i was doing with ginger  
um for i in tx so for so the object which youtube 
transcript api dot gets i've just called tx so  
for each item in that object so it's basically 
returning a list for each item in that list  
um we want to do this so this is the bit 
that you wouldn't see on the documentation  
and this is the bit that actually picks out the 
text if you don't do this you'll end up with  
a json dictionary and you'll end up with start 
times end times um and so on it won't provide you  
with what you need if you're planning on working 
with just the actual text for instance if you're  
about to do something with nlp um maybe it's not 
sentiment analysis well maybe sentiment analysis  
um you may be creating a bag of words analyzing 
part of speech etc etc so uh what we've got here  
is text so we're just like putting one line of 
text and then we're going to append it to our list  
and um also what i'm going to do is open a 
new file or append and then i'm going to write  
the text from the current line as we go 
through the video so obviously the video runs  
that way because of the timings so as we go 
through time we keep getting a new line a new  
line a new line new line new line so and that's 
why i've put new line here without the new line  
you just end up with a massive long you just 
imagine 40 minute video just with one line of text  
not good right then all i've done in it just 
for um a little bit of a bonus i've added in  
chrome sklearn feature extraction 
just added in account vectorizer  
and it converts a collection of text 
documents to a matrix of token accounts  
and yeah from here you could go and do 
your own thing with um yeah nlp and so on  
you could even reject the video if it didn't 
have a certain phrase so you could go off  
and get subtitles from many many videos 
and rather than watching um 20 videos on
climate change you could get the 
20 transcripts and then you could  
you could just search each of those 
transcripts for certain words such as  
polar bear maybe only three of those videos have 
got the word polar bear so rather than watching  
20 videos you then know that you've only got to 
watch those three videos so this isn't all about  
hacking or web scraping or doing anything naughty 
it can be used purely to save your time and  
i know youtube would probably like you to watch 
20 20 videos that all last an hour long but um  
i think they would still be happy if you're only 
watching three videos they're an hour long each  
you know three hours is better than nothing um and 
you probably wouldn't sit down and watch 20 hours  
worth of videos anyway so you then what would 
you do i don't know you'd probably just go off  
and read a book so with that all that being said 
i think it's time to actually demonstrate the code  
so what i'm just going to do is just i'll just 
comment that comment out this bit for starters  
and what we'll do is we will just run the main 
code which should just generate us a text file  
so if i just bring up the sidebar 
and you see i've already run it once  
so let's just delete that text 
file and um yeah let's run it so
it's run and that was when i um run my code within 
vs code it sends all this output to the screen  
um and it runs successfully no 
error message and i know it runs  
successfully because i've got that op 
text file back and let's have a look so
hi everyone welcome to this lecture series 
on osi i file storage service and in this  
particular module we're going to introduce 
the file storage service and look at it  
some of its characteristics my name is ryan i'm 
part of the oracle cloud infrastructure team  
so that's pretty good i mean there's 
very few kind of um errors there  
last week i was adding subtitles to my videos 
about ginger and that's obviously j-i-n-j-a and  
yeah the subtitles were just calling it ginger as 
in g-i-n-g-e-r and had to change that everywhere  
ginger obviously being a plant or a flavor flavor 
of biscuits right so that is the output file which  
um yeah okay so so far so good before we run let's 
just delete that and i'll run that on it let's  
just uh test it on them on a different come on 
delete i've made the font really big and it's um  
made it a bit harder to do 
what i normally do so um
right okay so let's just get um 
another youtube video youtube
and anyone got any requests
um
tell you what let's do one of my videos so if 
you let's just um there's two ways of doing it  
so what the an easy way to actually get it 
is just to click share and then just go in  
here and that's the video id there so um i said 
it was easy there you go right right click copy  
and um let's replace what i had in here 
before with my new video id so there we go  
and this should work because i have done 
the subtitles for it so if we run it
may take a while wow that was only about 
what two seconds and um wow because  
that's interesting i've actually enabled german 
subtitles on my on my most recent videos and  
it's actually gone off and got the german and 
i think there's some characters missing from  
the whether it is i think it's 
probably missing the on lives  
so you you've got the german translation there 
because it tries german first uh if i take  
out german from there it will just obviously 
just get the english so i'm gonna delete that  
run it one more time just to 
prove that it does multi language  
and um well it's even got i don't 
know why it's putting this in here
oh it's not liking the new line characters is it
maybe
don't know that's um
in fact let's just open that with uh
let's just open that with a different text editor 
shall we i'm just going to open that with um
let's just open it with word pud  
this is uh i'm back on the windows machine 
because i'm i've been having some issues with  
flickering on the screen using um my linux mint 
and obs so here we go yeah hello everybody today  
we're looking at how to scrape videos content 
from youtube so what i mean is we're going to  
download the video so yeah technically you could 
call it scraping if you want or scrapping if  
yeah don't get me started on scrapping 
so um this is just how it's rendered in  
vs code so don't worry about that it opens 
fine in a text editor a normal text editor  
so there we go and um right who wants to just run 
a little bit of natural language process well it's  
not we're not really doing anything clever all 
we're just doing is we're running count vectorizer  
which will um creates vectorizer 
object and then it prints you  
identified unique words along with their indices 
so um let's just run that and that'll print to  
the screen so there we go that's all the 
unique words uh with their indices so
if we wanted we could check this text for 
a certain word um we could check it for
scraping
scrape scraping
so there we go i hope this has been interesting um 
the whole reason i made this video was because i  
had a subscriber ask if following on from 
the previous videos where i've extracted  
text from uh from the images created from uh 
stills taken from the video the subscriber said  
could i extract the transcripts programmatically 
and obviously this is it this is the solution so
youtube transcript api and the benefit or 
the beauty of it is you don't even need to  
register for an api key and an auth token and 
so on this is this is usable on any video so um  
yeah obviously youtube haven't um blocked 
it or anything so um i know there's a bit  
about proxies and so on but um for all intents and 
purposes that's that's not needed here not in this  
example or not from the uk so perhaps if you're 
trying to access this from china or somewhere  
maybe you need to use proxy i don't know um but 
there we go so hopefully you've enjoyed this  
and found it useful don't forget to as usual 
subscribe thumbs up um because of the algos thank
you
hello is that dr pi? yeah speaking, can you get us 
some transcripts from youtube? transcripts? yeah  
okay I can do that! we will be awfully grateful 
if you can do this lovely job all right thank you
hello everybody in this video we're going 
to look at how to get the transcript of a  
youtube video automatically so we're going to be 
using python code to do this so let's look at how  
we're going to get about it so firstly we want 
to get the id of the youtube video so the id is  
the last part of the url of the video that you're 
watching that you want to get the transcript from  
next we want to uh we want to add the id to our 
python code and once we've done that we can then  
pass the output and we can save it to a text 
file or we can do some NLP with it if we want so  
we've all got our own reasons for passing and 
for actually extracting the transcript anyway um  
obviously there's manual ways of doing this 
and there are browser extensions but we want  
to do this programmatically and also we 
may want to do it for many many videos  
so you don't want to sit there keep clicking 
right clicking copy and pasting and so on so
as i said the part of the i part 
of the url which represents the id  
which you will need to get is this so after the 
equals and there's a little gotcha actually which  
i'll show you in the code in a minute where 
if it begins if it begins with a backslash  
so that's what you need to do and once you've got 
the video id then it's time to install pip install  
youtube dash transcript dash api and if you're 
doing it the normal old-fashioned way pip install  
youtube underscore transcript underscore api or 
if you're using conda conda install c conda dash  
forge youtube dash transcript dash api so when you 
do it on conda you've just got hyphens instead of  
underscores this is the conda page it was last 
updated three months ago so it's very recent  
it's quite a new project actually only 248 
downloads anyway when you've installed it  
or when you want to install it using conda you'll 
get a screen like this and it'll prompt you that  
you need to uh update or install the following 
packages ca certificates certified and conda  
and just say yes to agree to these they're quite 
small um right this is the this is a screenshot of  
the of the uh the the this is a screenshot of the 
documentation couldn't get my words out then not  
getting seen honestly it's just uh like a coffee 
right from youtube underscore transcript api  
import use youtube transcript api so just copy and 
paste that from the documentation then this is the  
good bit youtube youtube transcript api dot get 
underscore transcript and then a brackets video id  
so there's no um there's no quotes or anything for 
that so just paste it straight into the brackets  
and if you were to copy what they've shown 
here you would actually just get a large  
um large python dictionary insert or multiple 
python dictionaries inside the list so  
in a minute i'll show you some code and 
i'll show you how to actually extract that  
if you want different languages you 
can specify different languages so  
what it does is actually checks in sequence so 
it will check if you put d e then it will check  
for a german transcript first and then english 
and so on and so on so you can put many many  
different flavors there and uh yeah it will 
try and get the one that you want in sequence  
in order of priority um right so this is some 
code this is what we will get when we run it so  
this is just a little taster and if you like 
this code or if you like the projects rather  
um then donate if possible to jonas de poire at 
web dot d e uh go to the go to the documentation  
and you will see his donate button there and 
if you like what i do then don't forget to  
check out red and green which is my website and 
there's links to various different things we got  
a bit of network automation my github page my 
blog where i just put a few technical notes  
rather than more than a few even data 
extraction challenges using jquery  
and working with json and apis and there we 
go so if you'd like to see some actual code  
okay so we've done the conda install we've 
installed youtube transcript api if you want to do  
it with pip then you don't need to do the cond a 
bit so this is where we do the import the module  
from youtube transcript api import youtube 
transcript api then um just a quick note here  
you can have a list of just a couple of settings 
so as i mentioned just now this is a note about  
the language settings and um also with regard to 
the video id if the video id starts with a hyphen  
you'll have to mask the hyphen using the
backslash so yeah if it's got a hyphen at the 
start you just need to put a backslash otherwise  
the uh the code will think that it's an 
argument or think it's an argument name  
so the main code if you're ready to see 
that well i've already got an extracted  
video id so all i've done is just found a 
video i found one that had subtitles and  
if it doesn't have subtitles you're getting 
that or you won't get an error but you'll  
get a notification saying that it it's not 
possible to get subtitles for this video  
so the main code out ls so that's going to be 
the list which captures the output of all of the  
subtitles so tx equals youtube transcripts 
api dot get trans get underscore transcript  
and there we can see um the parameters that you 
pass to it so you can pass to the video id the  
languages and it can also cope with proxies and 
cookies the default is no proxy and no cookies  
so the default is also english if you don't 
specify languages either so i could actually  
leave that out well i'm just for demonstration 
purposes i'm going to leave d e in here  
and you'll see what happens because when d 
e is not available it will then just go off  
and get english um be aware that these are two 
letter country codes uh what was i using the other  
day something was using three-letter country 
codes i think that may have been i don't know  
was it ginger something like that not not ginger 
itself but uh something i was doing with ginger  
um for i in tx so for so the object which youtube 
transcript api dot gets i've just called tx so  
for each item in that object so it's basically 
returning a list for each item in that list  
um we want to do this so this is the bit 
that you wouldn't see on the documentation  
and this is the bit that actually picks out the 
text if you don't do this you'll end up with  
a json dictionary and you'll end up with start 
times end times um and so on it won't provide you  
with what you need if you're planning on working 
with just the actual text for instance if you're  
about to do something with nlp um maybe it's not 
sentiment analysis well maybe sentiment analysis  
um you may be creating a bag of words analyzing 
part of speech etc etc so uh what we've got here  
is text so we're just like putting one line of 
text and then we're going to append it to our list  
and um also what i'm going to do is open a 
new file or append and then i'm going to write  
the text from the current line as we go 
through the video so obviously the video runs  
that way because of the timings so as we go 
through time we keep getting a new line a new  
line a new line new line new line so and that's 
why i've put new line here without the new line  
you just end up with a massive long you just 
imagine 40 minute video just with one line of text  
not good right then all i've done in it just 
for um a little bit of a bonus i've added in  
chrome sklearn feature extraction 
just added in account vectorizer  
and it converts a collection of text 
documents to a matrix of token accounts  
and yeah from here you could go and do 
your own thing with um yeah nlp and so on  
you could even reject the video if it didn't 
have a certain phrase so you could go off  
and get subtitles from many many videos 
and rather than watching um 20 videos on
climate change you could get the 
20 transcripts and then you could  
you could just search each of those 
transcripts for certain words such as  
polar bear maybe only three of those videos have 
got the word polar bear so rather than watching  
20 videos you then know that you've only got to 
watch those three videos so this isn't all about  
hacking or web scraping or doing anything naughty 
it can be used purely to save your time and  
i know youtube would probably like you to watch 
20 20 videos that all last an hour long but um  
i think they would still be happy if you're only 
watching three videos they're an hour long each  
you know three hours is better than nothing um and 
you probably wouldn't sit down and watch 20 hours  
worth of videos anyway so you then what would 
you do i don't know you'd probably just go off  
and read a book so with that all that being said 
i think it's time to actually demonstrate the code  
so what i'm just going to do is just i'll just 
comment that comment out this bit for starters  
and what we'll do is we will just run the main 
code which should just generate us a text file  
so if i just bring up the sidebar 
and you see i've already run it once  
so let's just delete that text 
file and um yeah let's run it so
it's run and that was when i um run my code within 
vs code it sends all this output to the screen  
um and it runs successfully no 
error message and i know it runs  
successfully because i've got that op 
text file back and let's have a look so
hi everyone welcome to this lecture series 
on osi i file storage service and in this  
particular module we're going to introduce 
the file storage service and look at it  
some of its characteristics my name is ryan i'm 
part of the oracle cloud infrastructure team  
so that's pretty good i mean there's 
very few kind of um errors there  
last week i was adding subtitles to my videos 
about ginger and that's obviously j-i-n-j-a and  
yeah the subtitles were just calling it ginger as 
in g-i-n-g-e-r and had to change that everywhere  
ginger obviously being a plant or a flavor flavor 
of biscuits right so that is the output file which  
um yeah okay so so far so good before we run let's 
just delete that and i'll run that on it let's  
just uh test it on them on a different come on 
delete i've made the font really big and it's um  
made it a bit harder to do 
what i normally do so um
right okay so let's just get um 
another youtube video youtube
and anyone got any requests
um
tell you what let's do one of my videos so if 
you let's just um there's two ways of doing it  
so what the an easy way to actually get it 
is just to click share and then just go in  
here and that's the video id there so um i said 
it was easy there you go right right click copy  
and um let's replace what i had in here 
before with my new video id so there we go  
and this should work because i have done 
the subtitles for it so if we run it
may take a while wow that was only about 
what two seconds and um wow because  
that's interesting i've actually enabled german 
subtitles on my on my most recent videos and  
it's actually gone off and got the german and 
i think there's some characters missing from  
the whether it is i think it's 
probably missing the on lives  
so you you've got the german translation there 
because it tries german first uh if i take  
out german from there it will just obviously 
just get the english so i'm gonna delete that  
run it one more time just to 
prove that it does multi language  
and um well it's even got i don't 
know why it's putting this in here
oh it's not liking the new line characters is it
maybe
don't know that's um
in fact let's just open that with uh
let's just open that with a different text editor 
shall we i'm just going to open that with um
let's just open it with word pud  
this is uh i'm back on the windows machine 
because i'm i've been having some issues with  
flickering on the screen using um my linux mint 
and obs so here we go yeah hello everybody today  
we're looking at how to scrape videos content 
from youtube so what i mean is we're going to  
download the video so yeah technically you could 
call it scraping if you want or scrapping if  
yeah don't get me started on scrapping 
so um this is just how it's rendered in  
vs code so don't worry about that it opens 
fine in a text editor a normal text editor  
so there we go and um right who wants to just run 
a little bit of natural language process well it's  
not we're not really doing anything clever all 
we're just doing is we're running count vectorizer  
which will um creates vectorizer 
object and then it prints you  
identified unique words along with their indices 
so um let's just run that and that'll print to  
the screen so there we go that's all the 
unique words uh with their indices so
if we wanted we could check this text for 
a certain word um we could check it for
scraping
scrape scraping
so there we go i hope this has been interesting um 
the whole reason i made this video was because i  
had a subscriber ask if following on from 
the previous videos where i've extracted  
text from uh from the images created from uh 
stills taken from the video the subscriber said  
could i extract the transcripts programmatically 
and obviously this is it this is the solution so
youtube transcript api and the benefit or 
the beauty of it is you don't even need to  
register for an api key and an auth token and 
so on this is this is usable on any video so um  
yeah obviously youtube haven't um blocked 
it or anything so um i know there's a bit  
about proxies and so on but um for all intents and 
purposes that's that's not needed here not in this  
example or not from the uk so perhaps if you're 
trying to access this from china or somewhere  
maybe you need to use proxy i don't know um but 
there we go so hopefully you've enjoyed this  
and found it useful don't forget to as usual 
subscribe thumbs up um because of the algos thank
you
hello is that dr pi? yeah speaking, can you get us 
some transcripts from youtube? transcripts? yeah  
okay I can do that! we will be awfully grateful 
if you can do this lovely job all right thank you
hello everybody in this video we're going 
to look at how to get the transcript of a  
youtube video automatically so we're going to be 
using python code to do this so let's look at how  
we're going to get about it so firstly we want 
to get the id of the youtube video so the id is  
the last part of the url of the video that you're 
watching that you want to get the transcript from  
next we want to uh we want to add the id to our 
python code and once we've done that we can then  
pass the output and we can save it to a text 
file or we can do some NLP with it if we want so  
we've all got our own reasons for passing and 
for actually extracting the transcript anyway um  
obviously there's manual ways of doing this 
and there are browser extensions but we want  
to do this programmatically and also we 
may want to do it for many many videos  
so you don't want to sit there keep clicking 
right clicking copy and pasting and so on so
as i said the part of the i part 
of the url which represents the id  
which you will need to get is this so after the 
equals and there's a little gotcha actually which  
i'll show you in the code in a minute where 
if it begins if it begins with a backslash  
so that's what you need to do and once you've got 
the video id then it's time to install pip install  
youtube dash transcript dash api and if you're 
doing it the normal old-fashioned way pip install  
youtube underscore transcript underscore api or 
if you're using conda conda install c conda dash  
forge youtube dash transcript dash api so when you 
do it on conda you've just got hyphens instead of  
underscores this is the conda page it was last 
updated three months ago so it's very recent  
it's quite a new project actually only 248 
downloads anyway when you've installed it  
or when you want to install it using conda you'll 
get a screen like this and it'll prompt you that  
you need to uh update or install the following 
packages ca certificates certified and conda  
and just say yes to agree to these they're quite 
small um right this is the this is a screenshot of  
the of the uh the the this is a screenshot of the 
documentation couldn't get my words out then not  
getting seen honestly it's just uh like a coffee 
right from youtube underscore transcript api  
import use youtube transcript api so just copy and 
paste that from the documentation then this is the  
good bit youtube youtube transcript api dot get 
underscore transcript and then a brackets video id  
so there's no um there's no quotes or anything for 
that so just paste it straight into the brackets  
and if you were to copy what they've shown 
here you would actually just get a large  
um large python dictionary insert or multiple 
python dictionaries inside the list so  
in a minute i'll show you some code and 
i'll show you how to actually extract that  
if you want different languages you 
can specify different languages so  
what it does is actually checks in sequence so 
it will check if you put d e then it will check  
for a german transcript first and then english 
and so on and so on so you can put many many  
different flavors there and uh yeah it will 
try and get the one that you want in sequence  
in order of priority um right so this is some 
code this is what we will get when we run it so  
this is just a little taster and if you like 
this code or if you like the projects rather  
um then donate if possible to jonas de poire at 
web dot d e uh go to the go to the documentation  
and you will see his donate button there and 
if you like what i do then don't forget to  
check out red and green which is my website and 
there's links to various different things we got  
a bit of network automation my github page my 
blog where i just put a few technical notes  
rather than more than a few even data 
extraction challenges using jquery  
and working with json and apis and there we 
go so if you'd like to see some actual code  
okay so we've done the conda install we've 
installed youtube transcript api if you want to do  
it with pip then you don't need to do the cond a 
bit so this is where we do the import the module  
from youtube transcript api import youtube 
transcript api then um just a quick note here  
you can have a list of just a couple of settings 
so as i mentioned just now this is a note about  
the language settings and um also with regard to 
the video id if the video id starts with a hyphen  
you'll have to mask the hyphen using the
backslash so yeah if it's got a hyphen at the 
start you just need to put a backslash otherwise  
the uh the code will think that it's an 
argument or think it's an argument name  
so the main code if you're ready to see 
that well i've already got an extracted  
video id so all i've done is just found a 
video i found one that had subtitles and  
if it doesn't have subtitles you're getting 
that or you won't get an error but you'll  
get a notification saying that it it's not 
possible to get subtitles for this video  
so the main code out ls so that's going to be 
the list which captures the output of all of the  
subtitles so tx equals youtube transcripts 
api dot get trans get underscore transcript  
and there we can see um the parameters that you 
pass to it so you can pass to the video id the  
languages and it can also cope with proxies and 
cookies the default is no proxy and no cookies  
so the default is also english if you don't 
specify languages either so i could actually  
leave that out well i'm just for demonstration 
purposes i'm going to leave d e in here  
and you'll see what happens because when d 
e is not available it will then just go off  
and get english um be aware that these are two 
letter country codes uh what was i using the other  
day something was using three-letter country 
codes i think that may have been i don't know  
was it ginger something like that not not ginger 
itself but uh something i was doing with ginger  
um for i in tx so for so the object which youtube 
transcript api dot gets i've just called tx so  
for each item in that object so it's basically 
returning a list for each item in that list  
um we want to do this so this is the bit 
that you wouldn't see on the documentation  
and this is the bit that actually picks out the 
text if you don't do this you'll end up with  
a json dictionary and you'll end up with start 
times end times um and so on it won't provide you  
with what you need if you're planning on working 
with just the actual text for instance if you're  
about to do something with nlp um maybe it's not 
sentiment analysis well maybe sentiment analysis  
um you may be creating a bag of words analyzing 
part of speech etc etc so uh what we've got here  
is text so we're just like putting one line of 
text and then we're going to append it to our list  
and um also what i'm going to do is open a 
new file or append and then i'm going to write  
the text from the current line as we go 
through the video so obviously the video runs  
that way because of the timings so as we go 
through time we keep getting a new line a new  
line a new line new line new line so and that's 
why i've put new line here without the new line  
you just end up with a massive long you just 
imagine 40 minute video just with one line of text  
not good right then all i've done in it just 
for um a little bit of a bonus i've added in  
chrome sklearn feature extraction 
just added in account vectorizer  
and it converts a collection of text 
documents to a matrix of token accounts  
and yeah from here you could go and do 
your own thing with um yeah nlp and so on  
you could even reject the video if it didn't 
have a certain phrase so you could go off  
and get subtitles from many many videos 
and rather than watching um 20 videos on
climate change you could get the 
20 transcripts and then you could  
you could just search each of those 
transcripts for certain words such as  
polar bear maybe only three of those videos have 
got the word polar bear so rather than watching  
20 videos you then know that you've only got to 
watch those three videos so this isn't all about  
hacking or web scraping or doing anything naughty 
it can be used purely to save your time and  
i know youtube would probably like you to watch 
20 20 videos that all last an hour long but um  
i think they would still be happy if you're only 
watching three videos they're an hour long each  
you know three hours is better than nothing um and 
you probably wouldn't sit down and watch 20 hours  
worth of videos anyway so you then what would 
you do i don't know you'd probably just go off  
and read a book so with that all that being said 
i think it's time to actually demonstrate the code  
so what i'm just going to do is just i'll just 
comment that comment out this bit for starters  
and what we'll do is we will just run the main 
code which should just generate us a text file  
so if i just bring up the sidebar 
and you see i've already run it once  
so let's just delete that text 
file and um yeah let's run it so
it's run and that was when i um run my code within 
vs code it sends all this output to the screen  
um and it runs successfully no 
error message and i know it runs  
successfully because i've got that op 
text file back and let's have a look so
hi everyone welcome to this lecture series 
on osi i file storage service and in this  
particular module we're going to introduce 
the file storage service and look at it  
some of its characteristics my name is ryan i'm 
part of the oracle cloud infrastructure team  
so that's pretty good i mean there's 
very few kind of um errors there  
last week i was adding subtitles to my videos 
about ginger and that's obviously j-i-n-j-a and  
yeah the subtitles were just calling it ginger as 
in g-i-n-g-e-r and had to change that everywhere  
ginger obviously being a plant or a flavor flavor 
of biscuits right so that is the output file which  
um yeah okay so so far so good before we run let's 
just delete that and i'll run that on it let's  
just uh test it on them on a different come on 
delete i've made the font really big and it's um  
made it a bit harder to do 
what i normally do so um
right okay so let's just get um 
another youtube video youtube
and anyone got any requests
um
tell you what let's do one of my videos so if 
you let's just um there's two ways of doing it  
so what the an easy way to actually get it 
is just to click share and then just go in  
here and that's the video id there so um i said 
it was easy there you go right right click copy  
and um let's replace what i had in here 
before with my new video id so there we go  
and this should work because i have done 
the subtitles for it so if we run it
may take a while wow that was only about 
what two seconds and um wow because  
that's interesting i've actually enabled german 
subtitles on my on my most recent videos and  
it's actually gone off and got the german and 
i think there's some characters missing from  
the whether it is i think it's 
probably missing the on lives  
so you you've got the german translation there 
because it tries german first uh if i take  
out german from there it will just obviously 
just get the english so i'm gonna delete that  
run it one more time just to 
prove that it does multi language  
and um well it's even got i don't 
know why it's putting this in here
oh it's not liking the new line characters is it
maybe
don't know that's um
in fact let's just open that with uh
let's just open that with a different text editor 
shall we i'm just going to open that with um
let's just open it with word pud  
this is uh i'm back on the windows machine 
because i'm i've been having some issues with  
flickering on the screen using um my linux mint 
and obs so here we go yeah hello everybody today  
we're looking at how to scrape videos content 
from youtube so what i mean is we're going to  
download the video so yeah technically you could 
call it scraping if you want or scrapping if  
yeah don't get me started on scrapping 
so um this is just how it's rendered in  
vs code so don't worry about that it opens 
fine in a text editor a normal text editor  
so there we go and um right who wants to just run 
a little bit of natural language process well it's  
not we're not really doing anything clever all 
we're just doing is we're running count vectorizer  
which will um creates vectorizer 
object and then it prints you  
identified unique words along with their indices 
so um let's just run that and that'll print to  
the screen so there we go that's all the 
unique words uh with their indices so
if we wanted we could check this text for 
a certain word um we could check it for
scraping
scrape scraping
so there we go i hope this has been interesting um 
the whole reason i made this video was because i  
had a subscriber ask if following on from 
the previous videos where i've extracted  
text from uh from the images created from uh 
stills taken from the video the subscriber said  
could i extract the transcripts programmatically 
and obviously this is it this is the solution so
youtube transcript api and the benefit or 
the beauty of it is you don't even need to  
register for an api key and an auth token and 
so on this is this is usable on any video so um  
yeah obviously youtube haven't um blocked 
it or anything so um i know there's a bit  
about proxies and so on but um for all intents and 
purposes that's that's not needed here not in this  
example or not from the uk so perhaps if you're 
trying to access this from china or somewhere  
maybe you need to use proxy i don't know um but 
there we go so hopefully you've enjoyed this  
and found it useful don't forget to as usual 
subscribe thumbs up um because of the algos thank
you
hello is that dr pi? yeah speaking, can you get us 
some transcripts from youtube? transcripts? yeah  
okay I can do that! we will be awfully grateful 
if you can do this lovely job all right thank you
hello everybody in this video we're going 
to look at how to get the transcript of a  
youtube video automatically so we're going to be 
using python code to do this so let's look at how  
we're going to get about it so firstly we want 
to get the id of the youtube video so the id is  
the last part of the url of the video that you're 
watching that you want to get the transcript from  
next we want to uh we want to add the id to our 
python code and once we've done that we can then  
pass the output and we can save it to a text 
file or we can do some NLP with it if we want so  
we've all got our own reasons for passing and 
for actually extracting the transcript anyway um  
obviously there's manual ways of doing this 
and there are browser extensions but we want  
to do this programmatically and also we 
may want to do it for many many videos  
so you don't want to sit there keep clicking 
right clicking copy and pasting and so on so
as i said the part of the i part 
of the url which represents the id  
which you will need to get is this so after the 
equals and there's a little gotcha actually which  
i'll show you in the code in a minute where 
if it begins if it begins with a backslash  
so that's what you need to do and once you've got 
the video id then it's time to install pip install  
youtube dash transcript dash api and if you're 
doing it the normal old-fashioned way pip install  
youtube underscore transcript underscore api or 
if you're using conda conda install c conda dash  
forge youtube dash transcript dash api so when you 
do it on conda you've just got hyphens instead of  
underscores this is the conda page it was last 
updated three months ago so it's very recent  
it's quite a new project actually only 248 
downloads anyway when you've installed it  
or when you want to install it using conda you'll 
get a screen like this and it'll prompt you that  
you need to uh update or install the following 
packages ca certificates certified and conda  
and just say yes to agree to these they're quite 
small um right this is the this is a screenshot of  
the of the uh the the this is a screenshot of the 
documentation couldn't get my words out then not  
getting seen honestly it's just uh like a coffee 
right from youtube underscore transcript api  
import use youtube transcript api so just copy and 
paste that from the documentation then this is the  
good bit youtube youtube transcript api dot get 
underscore transcript and then a brackets video id  
so there's no um there's no quotes or anything for 
that so just paste it straight into the brackets  
and if you were to copy what they've shown 
here you would actually just get a large  
um large python dictionary insert or multiple 
python dictionaries inside the list so  
in a minute i'll show you some code and 
i'll show you how to actually extract that  
if you want different languages you 
can specify different languages so  
what it does is actually checks in sequence so 
it will check if you put d e then it will check  
for a german transcript first and then english 
and so on and so on so you can put many many  
different flavors there and uh yeah it will 
try and get the one that you want in sequence  
in order of priority um right so this is some 
code this is what we will get when we run it so  
this is just a little taster and if you like 
this code or if you like the projects rather  
um then donate if possible to jonas de poire at 
web dot d e uh go to the go to the documentation  
and you will see his donate button there and 
if you like what i do then don't forget to  
check out red and green which is my website and 
there's links to various different things we got  
a bit of network automation my github page my 
blog where i just put a few technical notes  
rather than more than a few even data 
extraction challenges using jquery  
and working with json and apis and there we 
go so if you'd like to see some actual code  
okay so we've done the conda install we've 
installed youtube transcript api if you want to do  
it with pip then you don't need to do the cond a 
bit so this is where we do the import the module  
from youtube transcript api import youtube 
transcript api then um just a quick note here  
you can have a list of just a couple of settings 
so as i mentioned just now this is a note about  
the language settings and um also with regard to 
the video id if the video id starts with a hyphen  
you'll have to mask the hyphen using the
backslash so yeah if it's got a hyphen at the 
start you just need to put a backslash otherwise  
the uh the code will think that it's an 
argument or think it's an argument name  
so the main code if you're ready to see 
that well i've already got an extracted  
video id so all i've done is just found a 
video i found one that had subtitles and  
if it doesn't have subtitles you're getting 
that or you won't get an error but you'll  
get a notification saying that it it's not 
possible to get subtitles for this video  
so the main code out ls so that's going to be 
the list which captures the output of all of the  
subtitles so tx equals youtube transcripts 
api dot get trans get underscore transcript  
and there we can see um the parameters that you 
pass to it so you can pass to the video id the  
languages and it can also cope with proxies and 
cookies the default is no proxy and no cookies  
so the default is also english if you don't 
specify languages either so i could actually  
leave that out well i'm just for demonstration 
purposes i'm going to leave d e in here  
and you'll see what happens because when d 
e is not available it will then just go off  
and get english um be aware that these are two 
letter country codes uh what was i using the other  
day something was using three-letter country 
codes i think that may have been i don't know  
was it ginger something like that not not ginger 
itself but uh something i was doing with ginger  
um for i in tx so for so the object which youtube 
transcript api dot gets i've just called tx so  
for each item in that object so it's basically 
returning a list for each item in that list  
um we want to do this so this is the bit 
that you wouldn't see on the documentation  
and this is the bit that actually picks out the 
text if you don't do this you'll end up with  
a json dictionary and you'll end up with start 
times end times um and so on it won't provide you  
with what you need if you're planning on working 
with just the actual text for instance if you're  
about to do something with nlp um maybe it's not 
sentiment analysis well maybe sentiment analysis  
um you may be creating a bag of words analyzing 
part of speech etc etc so uh what we've got here  
is text so we're just like putting one line of 
text and then we're going to append it to our list  
and um also what i'm going to do is open a 
new file or append and then i'm going to write  
the text from the current line as we go 
through the video so obviously the video runs  
that way because of the timings so as we go 
through time we keep getting a new line a new  
line a new line new line new line so and that's 
why i've put new line here without the new line  
you just end up with a massive long you just 
imagine 40 minute video just with one line of text  
not good right then all i've done in it just 
for um a little bit of a bonus i've added in  
chrome sklearn feature extraction 
just added in account vectorizer  
and it converts a collection of text 
documents to a matrix of token accounts  
and yeah from here you could go and do 
your own thing with um yeah nlp and so on  
you could even reject the video if it didn't 
have a certain phrase so you could go off  
and get subtitles from many many videos 
and rather than watching um 20 videos on
climate change you could get the 
20 transcripts and then you could  
you could just search each of those 
transcripts for certain words such as  
polar bear maybe only three of those videos have 
got the word polar bear so rather than watching  
20 videos you then know that you've only got to 
watch those three videos so this isn't all about  
hacking or web scraping or doing anything naughty 
it can be used purely to save your time and  
i know youtube would probably like you to watch 
20 20 videos that all last an hour long but um  
i think they would still be happy if you're only 
watching three videos they're an hour long each  
you know three hours is better than nothing um and 
you probably wouldn't sit down and watch 20 hours  
worth of videos anyway so you then what would 
you do i don't know you'd probably just go off  
and read a book so with that all that being said 
i think it's time to actually demonstrate the code  
so what i'm just going to do is just i'll just 
comment that comment out this bit for starters  
and what we'll do is we will just run the main 
code which should just generate us a text file  
so if i just bring up the sidebar 
and you see i've already run it once  
so let's just delete that text 
file and um yeah let's run it so
it's run and that was when i um run my code within 
vs code it sends all this output to the screen  
um and it runs successfully no 
error message and i know it runs  
successfully because i've got that op 
text file back and let's have a look so
hi everyone welcome to this lecture series 
on osi i file storage service and in this  
particular module we're going to introduce 
the file storage service and look at it  
some of its characteristics my name is ryan i'm 
part of the oracle cloud infrastructure team  
so that's pretty good i mean there's 
very few kind of um errors there  
last week i was adding subtitles to my videos 
about ginger and that's obviously j-i-n-j-a and  
yeah the subtitles were just calling it ginger as 
in g-i-n-g-e-r and had to change that everywhere  
ginger obviously being a plant or a flavor flavor 
of biscuits right so that is the output file which  
um yeah okay so so far so good before we run let's 
just delete that and i'll run that on it let's  
just uh test it on them on a different come on 
delete i've made the font really big and it's um  
made it a bit harder to do 
what i normally do so um
right okay so let's just get um 
another youtube video youtube
and anyone got any requests
um
tell you what let's do one of my videos so if 
you let's just um there's two ways of doing it  
so what the an easy way to actually get it 
is just to click share and then just go in  
here and that's the video id there so um i said 
it was easy there you go right right click copy  
and um let's replace what i had in here 
before with my new video id so there we go  
and this should work because i have done 
the subtitles for it so if we run it
may take a while wow that was only about 
what two seconds and um wow because  
that's interesting i've actually enabled german 
subtitles on my on my most recent videos and  
it's actually gone off and got the german and 
i think there's some characters missing from  
the whether it is i think it's 
probably missing the on lives  
so you you've got the german translation there 
because it tries german first uh if i take  
out german from there it will just obviously 
just get the english so i'm gonna delete that  
run it one more time just to 
prove that it does multi language  
and um well it's even got i don't 
know why it's putting this in here
oh it's not liking the new line characters is it
maybe
don't know that's um
in fact let's just open that with uh
let's just open that with a different text editor 
shall we i'm just going to open that with um
let's just open it with word pud  
this is uh i'm back on the windows machine 
because i'm i've been having some issues with  
flickering on the screen using um my linux mint 
and obs so here we go yeah hello everybody today  
we're looking at how to scrape videos content 
from youtube so what i mean is we're going to  
download the video so yeah technically you could 
call it scraping if you want or scrapping if  
yeah don't get me started on scrapping 
so um this is just how it's rendered in  
vs code so don't worry about that it opens 
fine in a text editor a normal text editor  
so there we go and um right who wants to just run 
a little bit of natural language process well it's  
not we're not really doing anything clever all 
we're just doing is we're running count vectorizer  
which will um creates vectorizer 
object and then it prints you  
identified unique words along with their indices 
so um let's just run that and that'll print to  
the screen so there we go that's all the 
unique words uh with their indices so
if we wanted we could check this text for 
a certain word um we could check it for
scraping
scrape scraping
so there we go i hope this has been interesting um 
the whole reason i made this video was because i  
had a subscriber ask if following on from 
the previous videos where i've extracted  
text from uh from the images created from uh 
stills taken from the video the subscriber said  
could i extract the transcripts programmatically 
and obviously this is it this is the solution so
youtube transcript api and the benefit or 
the beauty of it is you don't even need to  
register for an api key and an auth token and 
so on this is this is usable on any video so um  
yeah obviously youtube haven't um blocked 
it or anything so um i know there's a bit  
about proxies and so on but um for all intents and 
purposes that's that's not needed here not in this  
example or not from the uk so perhaps if you're 
trying to access this from china or somewhere  
maybe you need to use proxy i don't know um but 
there we go so hopefully you've enjoyed this  
and found it useful don't forget to as usual 
subscribe thumbs up um because of the algos thank
you
hello is that dr pi? yeah speaking, can you get us 
some transcripts from youtube? transcripts? yeah  
okay I can do that! we will be awfully grateful 
if you can do this lovely job all right thank you
hello everybody in this video we're going 
to look at how to get the transcript of a  
youtube video automatically so we're going to be 
using python code to do this so let's look at how  
we're going to get about it so firstly we want 
to get the id of the youtube video so the id is  
the last part of the url of the video that you're 
watching that you want to get the transcript from  
next we want to uh we want to add the id to our 
python code and once we've done that we can then  
pass the output and we can save it to a text 
file or we can do some NLP with it if we want so  
we've all got our own reasons for passing and 
for actually extracting the transcript anyway um  
obviously there's manual ways of doing this 
and there are browser extensions but we want  
to do this programmatically and also we 
may want to do it for many many videos  
so you don't want to sit there keep clicking 
right clicking copy and pasting and so on so
as i said the part of the i part 
of the url which represents the id  
which you will need to get is this so after the 
equals and there's a little gotcha actually which  
i'll show you in the code in a minute where 
if it begins if it begins with a backslash  
so that's what you need to do and once you've got 
the video id then it's time to install pip install  
youtube dash transcript dash api and if you're 
doing it the normal old-fashioned way pip install  
youtube underscore transcript underscore api or 
if you're using conda conda install c conda dash  
forge youtube dash transcript dash api so when you 
do it on conda you've just got hyphens instead of  
underscores this is the conda page it was last 
updated three months ago so it's very recent  
it's quite a new project actually only 248 
downloads anyway when you've installed it  
or when you want to install it using conda you'll 
get a screen like this and it'll prompt you that  
you need to uh update or install the following 
packages ca certificates certified and conda  
and just say yes to agree to these they're quite 
small um right this is the this is a screenshot of  
the of the uh the the this is a screenshot of the 
documentation couldn't get my words out then not  
getting seen honestly it's just uh like a coffee 
right from youtube underscore transcript api  
import use youtube transcript api so just copy and 
paste that from the documentation then this is the  
good bit youtube youtube transcript api dot get 
underscore transcript and then a brackets video id  
so there's no um there's no quotes or anything for 
that so just paste it straight into the brackets  
and if you were to copy what they've shown 
here you would actually just get a large  
um large python dictionary insert or multiple 
python dictionaries inside the list so  
in a minute i'll show you some code and 
i'll show you how to actually extract that  
if you want different languages you 
can specify different languages so  
what it does is actually checks in sequence so 
it will check if you put d e then it will check  
for a german transcript first and then english 
and so on and so on so you can put many many  
different flavors there and uh yeah it will 
try and get the one that you want in sequence  
in order of priority um right so this is some 
code this is what we will get when we run it so  
this is just a little taster and if you like 
this code or if you like the projects rather  
um then donate if possible to jonas de poire at 
web dot d e uh go to the go to the documentation  
and you will see his donate button there and 
if you like what i do then don't forget to  
check out red and green which is my website and 
there's links to various different things we got  
a bit of network automation my github page my 
blog where i just put a few technical notes  
rather than more than a few even data 
extraction challenges using jquery  
and working with json and apis and there we 
go so if you'd like to see some actual code  
okay so we've done the conda install we've 
installed youtube transcript api if you want to do  
it with pip then you don't need to do the cond a 
bit so this is where we do the import the module  
from youtube transcript api import youtube 
transcript api then um just a quick note here  
you can have a list of just a couple of settings 
so as i mentioned just now this is a note about  
the language settings and um also with regard to 
the video id if the video id starts with a hyphen  
you'll have to mask the hyphen using the
backslash so yeah if it's got a hyphen at the 
start you just need to put a backslash otherwise  
the uh the code will think that it's an 
argument or think it's an argument name  
so the main code if you're ready to see 
that well i've already got an extracted  
video id so all i've done is just found a 
video i found one that had subtitles and  
if it doesn't have subtitles you're getting 
that or you won't get an error but you'll  
get a notification saying that it it's not 
possible to get subtitles for this video  
so the main code out ls so that's going to be 
the list which captures the output of all of the  
subtitles so tx equals youtube transcripts 
api dot get trans get underscore transcript  
and there we can see um the parameters that you 
pass to it so you can pass to the video id the  
languages and it can also cope with proxies and 
cookies the default is no proxy and no cookies  
so the default is also english if you don't 
specify languages either so i could actually  
leave that out well i'm just for demonstration 
purposes i'm going to leave d e in here  
and you'll see what happens because when d 
e is not available it will then just go off  
and get english um be aware that these are two 
letter country codes uh what was i using the other  
day something was using three-letter country 
codes i think that may have been i don't know  
was it ginger something like that not not ginger 
itself but uh something i was doing with ginger  
um for i in tx so for so the object which youtube 
transcript api dot gets i've just called tx so  
for each item in that object so it's basically 
returning a list for each item in that list  
um we want to do this so this is the bit 
that you wouldn't see on the documentation  
and this is the bit that actually picks out the 
text if you don't do this you'll end up with  
a json dictionary and you'll end up with start 
times end times um and so on it won't provide you  
with what you need if you're planning on working 
with just the actual text for instance if you're  
about to do something with nlp um maybe it's not 
sentiment analysis well maybe sentiment analysis  
um you may be creating a bag of words analyzing 
part of speech etc etc so uh what we've got here  
is text so we're just like putting one line of 
text and then we're going to append it to our list  
and um also what i'm going to do is open a 
new file or append and then i'm going to write  
the text from the current line as we go 
through the video so obviously the video runs  
that way because of the timings so as we go 
through time we keep getting a new line a new  
line a new line new line new line so and that's 
why i've put new line here without the new line  
you just end up with a massive long you just 
imagine 40 minute video just with one line of text  
not good right then all i've done in it just 
for um a little bit of a bonus i've added in  
chrome sklearn feature extraction 
just added in account vectorizer  
and it converts a collection of text 
documents to a matrix of token accounts  
and yeah from here you could go and do 
your own thing with um yeah nlp and so on  
you could even reject the video if it didn't 
have a certain phrase so you could go off  
and get subtitles from many many videos 
and rather than watching um 20 videos on
climate change you could get the 
20 transcripts and then you could  
you could just search each of those 
transcripts for certain words such as  
polar bear maybe only three of those videos have 
got the word polar bear so rather than watching  
20 videos you then know that you've only got to 
watch those three videos so this isn't all about  
hacking or web scraping or doing anything naughty 
it can be used purely to save your time and  
i know youtube would probably like you to watch 
20 20 videos that all last an hour long but um  
i think they would still be happy if you're only 
watching three videos they're an hour long each  
you know three hours is better than nothing um and 
you probably wouldn't sit down and watch 20 hours  
worth of videos anyway so you then what would 
you do i don't know you'd probably just go off  
and read a book so with that all that being said 
i think it's time to actually demonstrate the code  
so what i'm just going to do is just i'll just 
comment that comment out this bit for starters  
and what we'll do is we will just run the main 
code which should just generate us a text file  
so if i just bring up the sidebar 
and you see i've already run it once  
so let's just delete that text 
file and um yeah let's run it so
it's run and that was when i um run my code within 
vs code it sends all this output to the screen  
um and it runs successfully no 
error message and i know it runs  
successfully because i've got that op 
text file back and let's have a look so
hi everyone welcome to this lecture series 
on osi i file storage service and in this  
particular module we're going to introduce 
the file storage service and look at it  
some of its characteristics my name is ryan i'm 
part of the oracle cloud infrastructure team  
so that's pretty good i mean there's 
very few kind of um errors there  
last week i was adding subtitles to my videos 
about ginger and that's obviously j-i-n-j-a and  
yeah the subtitles were just calling it ginger as 
in g-i-n-g-e-r and had to change that everywhere  
ginger obviously being a plant or a flavor flavor 
of biscuits right so that is the output file which  
um yeah okay so so far so good before we run let's 
just delete that and i'll run that on it let's  
just uh test it on them on a different come on 
delete i've made the font really big and it's um  
made it a bit harder to do 
what i normally do so um
right okay so let's just get um 
another youtube video youtube
and anyone got any requests
um
tell you what let's do one of my videos so if 
you let's just um there's two ways of doing it  
so what the an easy way to actually get it 
is just to click share and then just go in  
here and that's the video id there so um i said 
it was easy there you go right right click copy  
and um let's replace what i had in here 
before with my new video id so there we go  
and this should work because i have done 
the subtitles for it so if we run it
may take a while wow that was only about 
what two seconds and um wow because  
that's interesting i've actually enabled german 
subtitles on my on my most recent videos and  
it's actually gone off and got the german and 
i think there's some characters missing from  
the whether it is i think it's 
probably missing the on lives  
so you you've got the german translation there 
because it tries german first uh if i take  
out german from there it will just obviously 
just get the english so i'm gonna delete that  
run it one more time just to 
prove that it does multi language  
and um well it's even got i don't 
know why it's putting this in here
oh it's not liking the new line characters is it
maybe
don't know that's um
in fact let's just open that with uh
let's just open that with a different text editor 
shall we i'm just going to open that with um
let's just open it with word pud  
this is uh i'm back on the windows machine 
because i'm i've been having some issues with  
flickering on the screen using um my linux mint 
and obs so here we go yeah hello everybody today  
we're looking at how to scrape videos content 
from youtube so what i mean is we're going to  
download the video so yeah technically you could 
call it scraping if you want or scrapping if  
yeah don't get me started on scrapping 
so um this is just how it's rendered in  
vs code so don't worry about that it opens 
fine in a text editor a normal text editor  
so there we go and um right who wants to just run 
a little bit of natural language process well it's  
not we're not really doing anything clever all 
we're just doing is we're running count vectorizer  
which will um creates vectorizer 
object and then it prints you  
identified unique words along with their indices 
so um let's just run that and that'll print to  
the screen so there we go that's all the 
unique words uh with their indices so
if we wanted we could check this text for 
a certain word um we could check it for
scraping
scrape scraping
so there we go i hope this has been interesting um 
the whole reason i made this video was because i  
had a subscriber ask if following on from 
the previous videos where i've extracted  
text from uh from the images created from uh 
stills taken from the video the subscriber said  
could i extract the transcripts programmatically 
and obviously this is it this is the solution so
youtube transcript api and the benefit or 
the beauty of it is you don't even need to  
register for an api key and an auth token and 
so on this is this is usable on any video so um  
yeah obviously youtube haven't um blocked 
it or anything so um i know there's a bit  
about proxies and so on but um for all intents and 
purposes that's that's not needed here not in this  
example or not from the uk so perhaps if you're 
trying to access this from china or somewhere  
maybe you need to use proxy i don't know um but 
there we go so hopefully you've enjoyed this  
and found it useful don't forget to as usual 
subscribe thumbs up um because of the algos thank
you
